<div align="center">

# ğŸ€ NBA Draft Data Scraper 

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![Scrapy](https://img.shields.io/badge/Scrapy-2.5-brightgreen?style=for-the-badge&logo=scrapy)](https://scrapy.org/)
[![Pandas](https://img.shields.io/badge/Pandas-Latest-purple?style=for-the-badge&logo=pandas)](https://pandas.pydata.org/)
[![Learning Project](https://img.shields.io/badge/Project%20Type-Learning-orange?style=for-the-badge)](https://github.com/yourusername)
[![MIT License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](https://opensource.org/licenses/)

> A web scraping learning project to automate NBA draft data collection for my NBA Draft Success Model analysis

[Overview](#-overview) â€¢ [Features](#-features) â€¢ [Installation](#-installation) â€¢ [Learning Journey](#-learning-journey) â€¢ [Contributing](#-contributing)

<img src="https://user-images.githubusercontent.com/your-path/draft-banner.png" alt="NBA Draft Banner" width="800">

</div>

## ğŸ“ Overview

This repository documents my journey learning web scraping through building an NBA draft data collector. Created as a solution to the time-consuming manual data collection process for my main [NBA Draft Success Model](your-link-here) project.

### ğŸ¯ Project Goals
- Learn web scraping fundamentals with Python & Scrapy
- Automate collection of historical NBA draft data
- Create reliable data pipeline for draft analysis
- Practice modern data engineering techniques

## ğŸŒŸ Features

```mermaid
graph TD
    A[Basketball Reference] -->|Web Scraping| B[Data Collection]
    B -->|Learning Process| C[Data Processing]
    C -->|Scrapy| D[Player Stats]
    C -->|Python| E[Draft History]
    D --> F[Draft Success Model]
    E --> F
    style A fill:#f9f,stroke:#333
    style F fill:#bbf,stroke:#333
```

### Current Capabilities
- ğŸ“Š Extract draft pick details and statistics
- ğŸ”„ Handle multi-team season data
- ğŸ“ˆ Process career trajectories
- ğŸ§¹ Basic data cleaning and formatting

### Learning Targets
- ğŸ¯ Rate limiting and ethical scraping
- ğŸ” Advanced CSS selectors
- ğŸ•·ï¸ Scrapy best practices
- ğŸ—ƒï¸ Efficient data storage

## âš™ï¸ Technical Architecture

### Development Stack
```python
# Core Technologies
STACK = {
    'Language': 'Python 3.8+',
    'Scraping': 'Scrapy 2.5',
    'Data Processing': 'Pandas',
    'Learning Resources': [
        'Scrapy Documentation',
        'Web Scraping Tutorials',
        'NBA Stats API Guides'
    ]
}
```

### Project Structure
```bash
NBA_Draft_Scraper/
â”œâ”€â”€ ğŸ•·ï¸ spiders/
â”‚   â””â”€â”€ nba_draft_spider.py     # Where I'm learning Scrapy
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ draft_data.csv          # Collected data
â”œâ”€â”€ ğŸ“ README.md                # Project documentation
â”œâ”€â”€ ğŸ”§ requirements.txt         # Dependencies
â””â”€â”€ âš™ï¸ settings.py              # Scrapy configurations
```

## ğŸš€ Installation

```bash
# Clone this learning project
git clone https://github.com/yourusername/NBA_Draft_Scraper.git

# Setup development environment
cd NBA_Draft_Scraper
pip install -r requirements.txt

# Run the scraper
scrapy crawl nba_draft_spider -o data/draft_data.csv
```

## ğŸ“Š Data Collection

### Sample Data Structure
### Sample Data Structure
| Column Name          | Description                            | Example     |
|----------------------|----------------------------------------|-------------|
| `player_id`          | Unique identifier for each player      | `1`         |
| `draft_year`         | Year the player was drafted            | `1995`      |
| `draft_round`        | Round in which the player was drafted  | `1`         |
| `draft_pick`         | Overall pick number in the draft       | `5`         |
| `team_drafted_by`    | Team that initially drafted the player | `GSW`       |
| `player_name`        | Name of the player                     | `Kevin Garnett` |
| `season_year`        | Season for the playerâ€™s stats          | `2004-05`   |
| `team`               | Team for the season                    | `MIN`       |
| `age`                | Playerâ€™s age during the season         | `28`        |
| `position`           | Position played during the season      | `PF`        |
| `games_played`       | Number of games played                 | `82`        |
| `games_started`      | Number of games started                | `82`        |
| `minutes_per_game`   | Average minutes per game               | `38.1`      |
| `points_per_game`    | Points scored per game                 | `22.2`      |
| `rebounds_per_game`  | Rebounds per game                      | `13.5`      |
| `assists_per_game`   | Assists per game                       | `5.7`       |
| `steals_per_game`    | Steals per game                        | `1.5`       |
| `blocks_per_game`    | Blocks per game                        | `1.4`       |
| `field_goal_percentage` | Field goal percentage             | `0.502`     |
| `three_point_percentage` | 3-point shooting percentage      | `0.240`     |
| `free_throw_percentage`  | Free throw percentage             | `0.811`     |
| `advanced_metrics`   | Advanced stats (e.g., PER, WS)         | `22.5 PER`  |
| `awards`             | Awards received during the season      | `MVP, All-NBA First Team` |

## ğŸ“š Learning Journey

### Progress Tracker
- [x] **Week 1:** Basic HTML parsing & Scrapy setup
- [x] **Week 2:** Handling pagination & nested data
- [ ] **Week 3:** Rate limiting & data validation
- [ ] **Week 4:** Error handling & recovery
- [ ] **Week 5:** Performance optimization

### Key Learnings
```python
lessons_learned = {
    'Technical': [
        'Web scraping fundamentals',
        'Data pipeline design',
        'Error handling patterns'
    ],
    'Personal Growth': [
        'Project planning',
        'Documentation practices',
        'Community engagement'
    ]
}
```

## ğŸ”® Future Directions

### Learning Goals
- [ ] Advanced Scrapy techniques
- [ ] Automated testing
- [ ] CI/CD implementation
- [ ] Data validation frameworks

### Project Evolution
- [ ] Enhanced error recovery
- [ ] Parallel processing
- [ ] API development
- [ ] Real-time updates

## ğŸ¤ Contributing

As a learning project, I welcome:
- Code reviews and feedback
- Optimization suggestions
- Documentation improvements
- Learning resources

## âš–ï¸ License

MIT License - See `LICENSE` for details

## âš ï¸ Disclaimer

This educational project follows Basketball Reference's terms of service and implements appropriate request delays.

---

<div align="center">

### ğŸ“š Learning Web Scraping Through NBA Analytics

[![GitHub followers](https://img.shields.io/github/followers/yourusername?style=social)](https://github.com/yourusername)
[![Project Stars](https://img.shields.io/github/stars/yourusername/NBA_Draft_Scraper?style=social)](https://github.com/yourusername/NBA_Draft_Scraper/stargazers)

</div>